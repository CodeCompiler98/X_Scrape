{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install googletrans==4.0.0-rc1 --quiet\n",
    "%pip install pandas --quiet\n",
    "%pip install nltk --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from googletrans import Translator\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Post ID                                       URL to tweet  \\\n",
      "0  1828837775791341997  https://x.com/JimmyMatthewsJr/status/182883777...   \n",
      "1  1828607916892422511  https://x.com/JimmyMatthewsJr/status/182860791...   \n",
      "2  1826979750856049026  https://x.com/TheVladsven/status/1826979750856...   \n",
      "3  1822071851960692972  https://x.com/TheVladsven/status/1822071851960...   \n",
      "4  1822069995565883579  https://x.com/TheVladsven/status/1822069995565...   \n",
      "5  1828212669670629624  https://x.com/Bloomer99999/status/182821266967...   \n",
      "6  1828060378711945505  https://x.com/EmilyMach5/status/18280603787119...   \n",
      "7  1813345368484073626  https://x.com/ScottWIsAnIdiot/status/181334536...   \n",
      "8  1829862469894058286  https://x.com/EmilyMach5/status/18298624698940...   \n",
      "9  1823835478480605640  https://x.com/acnewsitics/status/1823835478480...   \n",
      "\n",
      "                    creation_date  likes  \\\n",
      "0  Wed Aug 28 16:51:18 +0000 2024     29   \n",
      "1  Wed Aug 28 01:37:55 +0000 2024     21   \n",
      "2  Fri Aug 23 13:48:10 +0000 2024      1   \n",
      "3  Sat Aug 10 00:45:56 +0000 2024     19   \n",
      "4  Sat Aug 10 00:38:34 +0000 2024      8   \n",
      "5  Mon Aug 26 23:27:21 +0000 2024      2   \n",
      "6  Mon Aug 26 13:22:12 +0000 2024     17   \n",
      "7  Tue Jul 16 22:50:00 +0000 2024     10   \n",
      "8  Sat Aug 31 12:43:04 +0000 2024     54   \n",
      "9  Wed Aug 14 21:33:57 +0000 2024  56668   \n",
      "\n",
      "                                             caption  retweet_count  \\\n",
      "0  #TrumpIsUnfitForOffice #ArlingtonNationalCemet...             18   \n",
      "1  @thedesertginger I would not be surprised if h...              5   \n",
      "2  Respect marriage.  Donald Trump and Where's Me...              2   \n",
      "3  Pray for Trump.  He longs for North Korea and ...              3   \n",
      "4  Pray for Trump. He joined Hamas.   ðŸ‡ºðŸ‡¸ #trumpme...              2   \n",
      "5         #KamalaWinswithJoy https://t.co/k5dnunB1zQ              0   \n",
      "6  @VetsForRL Trump has used everyone around him ...             11   \n",
      "7  @ZionDarkwood @SteveLovesAmmo https://t.co/rJu...              5   \n",
      "8  @SteveSchmidtSES #TrumpDishonorsUS #TrumpIsUnf...             10   \n",
      "9        Cop vs the felon. ðŸ˜‚ https://t.co/LfXb1J7bBA           7448   \n",
      "\n",
      "   comment_count  view_count    poster_handle        poster_display_name  \\\n",
      "0              5        1793  JimmyMatthewsJr             Jimmy Matthews   \n",
      "1              1         863  JimmyMatthewsJr             Jimmy Matthews   \n",
      "2              2        1108      TheVladsven  Darth VladSven the Cat VI   \n",
      "3              4        3808      TheVladsven  Darth VladSven the Cat VI   \n",
      "4              2        2869      TheVladsven  Darth VladSven the Cat VI   \n",
      "5              0          58     Bloomer99999            Nabster ðŸ’™ðŸ‡ºðŸ‡¸ðŸ¦…ðŸ‡ºðŸ‡¸ðŸ’™   \n",
      "6              3         898       EmilyMach5                 Emily Mach   \n",
      "7              6        9438  ScottWIsAnIdiot   Scott Walker is An Idiot   \n",
      "8              1        1216       EmilyMach5                 Emily Mach   \n",
      "9           1546     1981822      acnewsitics                  Alex Cole   \n",
      "\n",
      "   poster_follower_count  poster_frequency  total_posts  \\\n",
      "0                   2613          5.376404        30624   \n",
      "1                   2613          5.376404        30624   \n",
      "2                    955         26.451581        26769   \n",
      "3                    955         26.451581        26769   \n",
      "4                    955         26.451581        26769   \n",
      "5                   5168         63.658373        66523   \n",
      "6                    397          1.938092         3068   \n",
      "7                   2476         14.871070        37371   \n",
      "8                    397          1.938092         3068   \n",
      "9                 283007         18.049858        38013   \n",
      "\n",
      "                                            hashtags  \\\n",
      "0  #TrumpIsUnfitForOffice, #ArlingtonNationalCeme...   \n",
      "1                             #TrumpIsUnfitForOffice   \n",
      "2  #TrumpIsDone, #KamalaHarris, #Kamala4President...   \n",
      "3                           #trumprally, #Kamala2024   \n",
      "4                           #trumprally, #Kamala2024   \n",
      "5                                 #KamalaWinswithJoy   \n",
      "6  #TrumpIsUnfitForOffice, #VeteransForHarrisWalz...   \n",
      "7                                                NaN   \n",
      "8          #TrumpDishonorsUS, #TrumpIsUnfitForOffice   \n",
      "9                                                NaN   \n",
      "\n",
      "                                      image_filename  \\\n",
      "0  Twitter_Scrape\\Target_Trump\\Anti\\Images\\eat_on...   \n",
      "1  Twitter_Scrape\\Target_Trump\\Anti\\Images\\vetera...   \n",
      "2  Twitter_Scrape\\Target_Trump\\Anti\\Images\\trump_...   \n",
      "3  Twitter_Scrape\\Target_Trump\\Anti\\Images\\trump_...   \n",
      "4  Twitter_Scrape\\Target_Trump\\Anti\\Images\\foreig...   \n",
      "5  Twitter_Scrape\\Target_Trump\\Anti\\Images\\trump_...   \n",
      "6  Twitter_Scrape\\Target_Trump\\Anti\\Images\\trump_...   \n",
      "7  Twitter_Scrape\\Target_Harris\\Anti\\Images\\setup...   \n",
      "8  Twitter_Scrape\\Target_Trump\\Anti\\Images\\trump_...   \n",
      "9  Twitter_Scrape\\Target_Trump\\Anti\\Images\\trump_...   \n",
      "\n",
      "                                        comment_file image+caption_target  \\\n",
      "0  Twitter_Scrape\\Target_Trump\\Anti\\Comments\\eat_...           anti-trump   \n",
      "1  Twitter_Scrape\\Target_Trump\\Anti\\Comments\\vete...           anti-trump   \n",
      "2                                                NaN           anti-trump   \n",
      "3  Twitter_Scrape\\Target_Trump\\Anti\\Comments\\trum...           anti-trump   \n",
      "4  Twitter_Scrape\\Target_Trump\\Anti\\Comments\\fore...           anti-trump   \n",
      "5                                                NaN           anti-trump   \n",
      "6  Twitter_Scrape\\Target_Trump\\Anti\\Comments\\trum...           anti-trump   \n",
      "7  Twitter_Scrape\\Target_Harris\\Anti\\Comments\\set...          anti-harris   \n",
      "8  Twitter_Scrape\\Target_Trump\\Anti\\Comments\\trum...           anti-trump   \n",
      "9  Twitter_Scrape\\Target_Trump\\Anti\\Comments\\trum...           anti-trump   \n",
      "\n",
      "  political_leaning  \n",
      "0                 D  \n",
      "1                 D  \n",
      "2                 D  \n",
      "3                 D  \n",
      "4                 D  \n",
      "5                 D  \n",
      "6                 D  \n",
      "7                 R  \n",
      "8                 D  \n",
      "9                 D  \n",
      "0      #TrumpIsUnfitForOffice #ArlingtonNationalCemet...\n",
      "1      @thedesertginger I would not be surprised if h...\n",
      "2      Respect marriage.  Donald Trump and Where's Me...\n",
      "3      Pray for Trump.  He longs for North Korea and ...\n",
      "4      Pray for Trump. He joined Hamas.   ðŸ‡ºðŸ‡¸ #trumpme...\n",
      "                             ...                        \n",
      "197          @MarioNawfal Right. https://t.co/mMDPYfhYYv\n",
      "198             @MarioNawfal Yup https://t.co/AjD9T3yUKf\n",
      "199    @nixongroyper @NickJFuentes Heâ€™s Alive https:/...\n",
      "200    @hhdogsitting @BklynP8triot @TristanSnell Poor...\n",
      "201    @azlibertad @funder No thanks. https://t.co/dW...\n",
      "Name: caption, Length: 202, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the absolute path to the CSV file\n",
    "csv_file_path = 'tweets.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "try:\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    # Display the DataFrame\n",
    "    print(df.head(10))\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {csv_file_path}\")\n",
    "except pd.errors.EmptyDataError:\n",
    "    print(\"The file is empty.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    \n",
    "#print out the caption collumn\n",
    "print(df['caption'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Post ID                                       URL to tweet  \\\n",
      "0  1828837775791341997  https://x.com/JimmyMatthewsJr/status/182883777...   \n",
      "1  1828607916892422511  https://x.com/JimmyMatthewsJr/status/182860791...   \n",
      "2  1826979750856049026  https://x.com/TheVladsven/status/1826979750856...   \n",
      "3  1822071851960692972  https://x.com/TheVladsven/status/1822071851960...   \n",
      "4  1822069995565883579  https://x.com/TheVladsven/status/1822069995565...   \n",
      "5  1828212669670629624  https://x.com/Bloomer99999/status/182821266967...   \n",
      "6  1828060378711945505  https://x.com/EmilyMach5/status/18280603787119...   \n",
      "7  1813345368484073626  https://x.com/ScottWIsAnIdiot/status/181334536...   \n",
      "8  1829862469894058286  https://x.com/EmilyMach5/status/18298624698940...   \n",
      "9  1823835478480605640  https://x.com/acnewsitics/status/1823835478480...   \n",
      "\n",
      "                    creation_date  likes  \\\n",
      "0  Wed Aug 28 16:51:18 +0000 2024     29   \n",
      "1  Wed Aug 28 01:37:55 +0000 2024     21   \n",
      "2  Fri Aug 23 13:48:10 +0000 2024      1   \n",
      "3  Sat Aug 10 00:45:56 +0000 2024     19   \n",
      "4  Sat Aug 10 00:38:34 +0000 2024      8   \n",
      "5  Mon Aug 26 23:27:21 +0000 2024      2   \n",
      "6  Mon Aug 26 13:22:12 +0000 2024     17   \n",
      "7  Tue Jul 16 22:50:00 +0000 2024     10   \n",
      "8  Sat Aug 31 12:43:04 +0000 2024     54   \n",
      "9  Wed Aug 14 21:33:57 +0000 2024  56668   \n",
      "\n",
      "                                    original_caption  retweet_count  \\\n",
      "0  #TrumpIsUnfitForOffice #ArlingtonNationalCemet...             18   \n",
      "1  @thedesertginger I would not be surprised if h...              5   \n",
      "2  Respect marriage.  Donald Trump and Where's Me...              2   \n",
      "3  Pray for Trump.  He longs for North Korea and ...              3   \n",
      "4  Pray for Trump. He joined Hamas.   ðŸ‡ºðŸ‡¸ #trumpme...              2   \n",
      "5         #KamalaWinswithJoy https://t.co/k5dnunB1zQ              0   \n",
      "6  @VetsForRL Trump has used everyone around him ...             11   \n",
      "7  @ZionDarkwood @SteveLovesAmmo https://t.co/rJu...              5   \n",
      "8  @SteveSchmidtSES #TrumpDishonorsUS #TrumpIsUnf...             10   \n",
      "9        Cop vs the felon. ðŸ˜‚ https://t.co/LfXb1J7bBA           7448   \n",
      "\n",
      "   comment_count  view_count    poster_handle        poster_display_name  ...  \\\n",
      "0              5        1793  JimmyMatthewsJr             Jimmy Matthews  ...   \n",
      "1              1         863  JimmyMatthewsJr             Jimmy Matthews  ...   \n",
      "2              2        1108      TheVladsven  Darth VladSven the Cat VI  ...   \n",
      "3              4        3808      TheVladsven  Darth VladSven the Cat VI  ...   \n",
      "4              2        2869      TheVladsven  Darth VladSven the Cat VI  ...   \n",
      "5              0          58     Bloomer99999            Nabster ðŸ’™ðŸ‡ºðŸ‡¸ðŸ¦…ðŸ‡ºðŸ‡¸ðŸ’™  ...   \n",
      "6              3         898       EmilyMach5                 Emily Mach  ...   \n",
      "7              6        9438  ScottWIsAnIdiot   Scott Walker is An Idiot  ...   \n",
      "8              1        1216       EmilyMach5                 Emily Mach  ...   \n",
      "9           1546     1981822      acnewsitics                  Alex Cole  ...   \n",
      "\n",
      "   poster_frequency  total_posts  \\\n",
      "0          5.376404        30624   \n",
      "1          5.376404        30624   \n",
      "2         26.451581        26769   \n",
      "3         26.451581        26769   \n",
      "4         26.451581        26769   \n",
      "5         63.658373        66523   \n",
      "6          1.938092         3068   \n",
      "7         14.871070        37371   \n",
      "8          1.938092         3068   \n",
      "9         18.049858        38013   \n",
      "\n",
      "                                            hashtags  \\\n",
      "0  #TrumpIsUnfitForOffice, #ArlingtonNationalCeme...   \n",
      "1                             #TrumpIsUnfitForOffice   \n",
      "2  #TrumpIsDone, #KamalaHarris, #Kamala4President...   \n",
      "3                           #trumprally, #Kamala2024   \n",
      "4                           #trumprally, #Kamala2024   \n",
      "5                                 #KamalaWinswithJoy   \n",
      "6  #TrumpIsUnfitForOffice, #VeteransForHarrisWalz...   \n",
      "7                                                      \n",
      "8          #TrumpDishonorsUS, #TrumpIsUnfitForOffice   \n",
      "9                                                      \n",
      "\n",
      "                                      image_filename  \\\n",
      "0  Twitter_Scrape\\Target_Trump\\Anti\\Images\\eat_on...   \n",
      "1  Twitter_Scrape\\Target_Trump\\Anti\\Images\\vetera...   \n",
      "2  Twitter_Scrape\\Target_Trump\\Anti\\Images\\trump_...   \n",
      "3  Twitter_Scrape\\Target_Trump\\Anti\\Images\\trump_...   \n",
      "4  Twitter_Scrape\\Target_Trump\\Anti\\Images\\foreig...   \n",
      "5  Twitter_Scrape\\Target_Trump\\Anti\\Images\\trump_...   \n",
      "6  Twitter_Scrape\\Target_Trump\\Anti\\Images\\trump_...   \n",
      "7  Twitter_Scrape\\Target_Harris\\Anti\\Images\\setup...   \n",
      "8  Twitter_Scrape\\Target_Trump\\Anti\\Images\\trump_...   \n",
      "9  Twitter_Scrape\\Target_Trump\\Anti\\Images\\trump_...   \n",
      "\n",
      "                                        comment_file image+caption_target  \\\n",
      "0  Twitter_Scrape\\Target_Trump\\Anti\\Comments\\eat_...           anti-trump   \n",
      "1  Twitter_Scrape\\Target_Trump\\Anti\\Comments\\vete...           anti-trump   \n",
      "2                                                NaN           anti-trump   \n",
      "3  Twitter_Scrape\\Target_Trump\\Anti\\Comments\\trum...           anti-trump   \n",
      "4  Twitter_Scrape\\Target_Trump\\Anti\\Comments\\fore...           anti-trump   \n",
      "5                                                NaN           anti-trump   \n",
      "6  Twitter_Scrape\\Target_Trump\\Anti\\Comments\\trum...           anti-trump   \n",
      "7  Twitter_Scrape\\Target_Harris\\Anti\\Comments\\set...          anti-harris   \n",
      "8  Twitter_Scrape\\Target_Trump\\Anti\\Comments\\trum...           anti-trump   \n",
      "9  Twitter_Scrape\\Target_Trump\\Anti\\Comments\\trum...           anti-trump   \n",
      "\n",
      "  political_leaning                       mentions urls  \\\n",
      "0                 D                                       \n",
      "1                 D               @thedesertginger        \n",
      "2                 D                                       \n",
      "3                 D                                       \n",
      "4                 D                                       \n",
      "5                 D                                       \n",
      "6                 D                     @VetsForRL        \n",
      "7                 R  @ZionDarkwood @SteveLovesAmmo        \n",
      "8                 D               @SteveSchmidtSES        \n",
      "9                 D                                       \n",
      "\n",
      "                                       caption_clean  \n",
      "0  #TrumpIsUnfitForOffice #ArlingtonNationalCemet...  \n",
      "1   I would not be surprised if he did this befor...  \n",
      "2  Respect marriage. Donald Trump and Where's Mel...  \n",
      "3  Pray for Trump. He longs for North Korea and h...  \n",
      "4  Pray for Trump. He joined Hamas. ðŸ‡ºðŸ‡¸ #trumpmelt...  \n",
      "5                                #KamalaWinswithJoy   \n",
      "6   Trump has used everyone around him for his pe...  \n",
      "7                                                     \n",
      "8   #TrumpDishonorsUS #TrumpIsUnfitForOffice Let'...  \n",
      "9                               Cop vs the felon. ðŸ˜‚   \n",
      "\n",
      "[10 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract and remove mentions\n",
    "df['mentions'] = df['caption'].apply(lambda x: ' '.join(re.findall(r'@\\w+', x)))\n",
    "df['caption_no_mentions'] = df['caption'].apply(lambda x: re.sub(r'@\\w+', '', x))\n",
    "\n",
    "# Extract hashtags\n",
    "df['new_hashtags'] = df['caption_no_mentions'].apply(lambda x: ' '.join(re.findall(r'#\\w+', x)))\n",
    "df['hashtags'] = df['hashtags'].mask(df['hashtags'].isna() | (df['hashtags'] == ''), df['new_hashtags'])\n",
    "df.drop(columns=['new_hashtags'], inplace=True)\n",
    "\n",
    "# Extract and remove URLs\n",
    "df['urls'] = df['caption_no_mentions'].apply(lambda x: ' '.join(re.findall(r'http\\S+', x)))\n",
    "df['urls'] = df['urls'].str.replace(r'https://t\\.co/\\w+', '', regex=True)\n",
    "df['caption_clean'] = df['caption_no_mentions'].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
    "\n",
    "#remove a ton of extra white space from caption_clean\n",
    "df['caption_clean'] = df['caption_clean'].str.replace(r'\\s+', ' ', regex=True)\n",
    "#drop filtering collumns\n",
    "df.drop(columns=['caption_no_mentions'], inplace=True)\n",
    "df.rename(columns={'caption': 'original_caption'}, inplace=True)\n",
    "print(df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Post ID                                       URL to tweet  \\\n",
      "0  1828837775791341997  https://x.com/JimmyMatthewsJr/status/182883777...   \n",
      "1  1828607916892422511  https://x.com/JimmyMatthewsJr/status/182860791...   \n",
      "2  1826979750856049026  https://x.com/TheVladsven/status/1826979750856...   \n",
      "3  1822071851960692972  https://x.com/TheVladsven/status/1822071851960...   \n",
      "4  1822069995565883579  https://x.com/TheVladsven/status/1822069995565...   \n",
      "\n",
      "                    creation_date  likes  \\\n",
      "0  Wed Aug 28 16:51:18 +0000 2024     29   \n",
      "1  Wed Aug 28 01:37:55 +0000 2024     21   \n",
      "2  Fri Aug 23 13:48:10 +0000 2024      1   \n",
      "3  Sat Aug 10 00:45:56 +0000 2024     19   \n",
      "4  Sat Aug 10 00:38:34 +0000 2024      8   \n",
      "\n",
      "                                    original_caption  retweet_count  \\\n",
      "0  #TrumpIsUnfitForOffice #ArlingtonNationalCemet...             18   \n",
      "1  @thedesertginger I would not be surprised if h...              5   \n",
      "2  Respect marriage.  Donald Trump and Where's Me...              2   \n",
      "3  Pray for Trump.  He longs for North Korea and ...              3   \n",
      "4  Pray for Trump. He joined Hamas.   ðŸ‡ºðŸ‡¸ #trumpme...              2   \n",
      "\n",
      "   comment_count  view_count    poster_handle        poster_display_name  ...  \\\n",
      "0              5        1793  JimmyMatthewsJr             Jimmy Matthews  ...   \n",
      "1              1         863  JimmyMatthewsJr             Jimmy Matthews  ...   \n",
      "2              2        1108      TheVladsven  Darth VladSven the Cat VI  ...   \n",
      "3              4        3808      TheVladsven  Darth VladSven the Cat VI  ...   \n",
      "4              2        2869      TheVladsven  Darth VladSven the Cat VI  ...   \n",
      "\n",
      "                                        comment_file  image+caption_target  \\\n",
      "0  Twitter_Scrape\\Target_Trump\\Anti\\Comments\\eat_...            anti-trump   \n",
      "1  Twitter_Scrape\\Target_Trump\\Anti\\Comments\\vete...            anti-trump   \n",
      "2                                                NaN            anti-trump   \n",
      "3  Twitter_Scrape\\Target_Trump\\Anti\\Comments\\trum...            anti-trump   \n",
      "4  Twitter_Scrape\\Target_Trump\\Anti\\Comments\\fore...            anti-trump   \n",
      "\n",
      "   political_leaning          mentions urls  \\\n",
      "0                  D                          \n",
      "1                  D  @thedesertginger        \n",
      "2                  D                          \n",
      "3                  D                          \n",
      "4                  D                          \n",
      "\n",
      "                                       caption_clean Positive Neutral  \\\n",
      "0  #TrumpIsUnfitForOffice #ArlingtonNationalCemet...    0.000   1.000   \n",
      "1   I would not be surprised if he did this befor...    0.000   0.868   \n",
      "2  Respect marriage. Donald Trump and Where's Mel...    0.274   0.679   \n",
      "3  Pray for Trump. He longs for North Korea and h...    0.141   0.859   \n",
      "4  Pray for Trump. He joined Hamas. ðŸ‡ºðŸ‡¸ #trumpmelt...    0.204   0.796   \n",
      "\n",
      "  Negative Compound  \n",
      "0    0.000   0.0000  \n",
      "1    0.132  -0.1695  \n",
      "2    0.047   0.8658  \n",
      "3    0.000   0.3182  \n",
      "4    0.000   0.3182  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\Jonah\n",
      "[nltk_data]     Dalton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Initialize the VADER sentiment analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Perform sentiment analysis on the 'Text in English language' column and save the results to a new column\n",
    "def analyze_sentiment(text):\n",
    "    sentiment_scores = sia.polarity_scores(text)\n",
    "    return sentiment_scores['pos'], sentiment_scores['neu'], sentiment_scores['neg'], sentiment_scores['compound']\n",
    "\n",
    "# Apply the analyze_sentiment function to the 'Text in English language' column\n",
    "df['Positive'], df['Neutral'], df['Negative'], df['Compound'] = zip(*df['caption_clean'].apply(analyze_sentiment))\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify the sentiment analysis\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Spacy Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (25.0)\n",
      "Collecting pip\n",
      "  Downloading pip-25.0.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (75.8.0)\n",
      "Requirement already satisfied: wheel in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (0.45.1)\n",
      "Downloading pip-25.0.1-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.8/1.8 MB 16.8 MB/s eta 0:00:00\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 25.0\n",
      "    Uninstalling pip-25.0:\n",
      "      Successfully uninstalled pip-25.0\n",
      "Successfully installed pip-25.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: spacy in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (from spacy) (8.3.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (from spacy) (0.13.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (from spacy) (4.67.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (from spacy) (2.9.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (from spacy) (75.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (from spacy) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (from spacy) (3.4.1)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (from jinja2->spacy) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\jonah dalton\\data_pipeline\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---- ----------------------------------- 1.3/12.8 MB 7.4 MB/s eta 0:00:02\n",
      "     ------- -------------------------------- 2.4/12.8 MB 6.4 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 3.4/12.8 MB 6.1 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 4.7/12.8 MB 5.8 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 5.8/12.8 MB 5.9 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 7.3/12.8 MB 6.0 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 8.7/12.8 MB 6.1 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 10.0/12.8 MB 6.1 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.3/12.8 MB 6.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.6/12.8 MB 6.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 6.1 MB/s eta 0:00:00\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "%pip install -U pip setuptools wheel\n",
    "%pip install -U spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Function to perform NER and separate entities by type\n",
    "def extract_entities_by_type(text):\n",
    "    doc = nlp(text)\n",
    "    persons = [entity.text for entity in doc.ents if entity.label_ == \"PERSON\"]\n",
    "    orgs = [entity.text for entity in doc.ents if entity.label_ == \"ORG\"]\n",
    "    gpes = [entity.text for entity in doc.ents if entity.label_ == \"GPE\"]\n",
    "    rel = [entity.text for entity in doc.ents if entity.label_ == \"NORP\"]\n",
    "    dat = [entity.text for entity in doc.ents if entity.label_ == \"DATE\"]\n",
    "    return persons, orgs, gpes, rel, dat\n",
    "\n",
    "# Apply the function to each tweet and store the results in separate columns\n",
    "df[['Persons', 'Organizations', 'Locations', 'Nationalities/religiious groups', 'Date']] = df['caption_clean'].apply(\n",
    "    lambda x: pd.Series(extract_entities_by_type(x))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1 (Postive Trump Sentiment): maga, trump2024, maga2024, vote, peanut, protect, trumpvance2024, say, january, patriots\n",
      "Topic #2 (Politcal Social Network): patriots, ifbap, trumpisunfitforoffice, let, day, trumpvance2024tosaveamerica, friends, free, ready, grow\n",
      "Topic #3 (Negative Candaite Sentiment): fuck, time, remember, america, kamala2024, waiting, yes, breaking, happy, vote\n",
      "Topic #4 (Voter readiness and mobilization): kamala, donald, like, election2024, real, thanks, think, elections2024, trumpvance2024, voted\n",
      "                                   topic_model_clean  \\\n",
      "0    trumpisunfitforoffice arlingtonnationalcemetery   \n",
      "1  i would not be surprised if he did this before...   \n",
      "2  respect marriage donald and wheres melania alw...   \n",
      "3  pray for he longs for north korea and his tub ...   \n",
      "4  pray for he joined hamas ðŸ‡ºðŸ‡¸ trumpmeltdown trum...   \n",
      "5                                  kamalawinswithjoy   \n",
      "6  has used everyone around him for his personal ...   \n",
      "7                                                      \n",
      "8  trumpdishonorsus trumpisunfitforoffice lets bu...   \n",
      "9                                 cop vs the felon ðŸ˜‚   \n",
      "\n",
      "                        topic_label  \n",
      "0           Politcal Social Network  \n",
      "1           Politcal Social Network  \n",
      "2  Voter readiness and mobilization  \n",
      "3       Negative Candaite Sentiment  \n",
      "4       Negative Candaite Sentiment  \n",
      "5           Postive Trump Sentiment  \n",
      "6           Politcal Social Network  \n",
      "7           Postive Trump Sentiment  \n",
      "8           Politcal Social Network  \n",
      "9           Postive Trump Sentiment  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import string\n",
    "import re\n",
    "\n",
    "# Sample dataset (replace this with your dataset)\n",
    "import os\n",
    "\n",
    "# Extract and remove mentions\n",
    "df['topic_model_clean'] = df['original_caption'].apply(lambda x: re.sub(r'@\\w+|http\\S+', '', x) if pd.notnull(x) else '')\n",
    "\n",
    "# List of words to remove (e.g., political keywords like 'trump')\n",
    "stop_words_custom = ['trump', 'president', 'new', ]\n",
    "\n",
    "# Preprocess text function (removes punctuation, stopwords, and other custom words)\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):  # Ensure the text is a string\n",
    "        # Convert text to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Remove punctuation\n",
    "        text = ''.join([char for char in text if char not in string.punctuation])\n",
    "        \n",
    "        # Remove custom stop words\n",
    "        text = ' '.join([word for word in text.split() if word not in stop_words_custom])\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply preprocessing only to the \"cleaned_caption\" column\n",
    "df['topic_model_clean'] = df['topic_model_clean'].apply(preprocess_text)\n",
    "\n",
    "# Vectorize the text using TF-IDF (you can adjust max_df, min_df to filter out too frequent/rare words)\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.80, min_df=3)\n",
    "X = tfidf_vectorizer.fit_transform(df['topic_model_clean'])\n",
    "\n",
    "# Train the LDA model (adjust num_topics, passes, iterations based on your dataset size)\n",
    "num_topics = 4 # Optimal number of topics, you can experiment with this\n",
    "lda_model = LatentDirichletAllocation(n_components=num_topics, max_iter=14, learning_method='online', random_state=42)\n",
    "\n",
    "# Fit the LDA model to the TF-IDF matrix\n",
    "lda_model.fit(X)\n",
    "\n",
    "# Get top words for each topic\n",
    "terms = tfidf_vectorizer.get_feature_names_out()\n",
    "n_top_words = 10\n",
    "topic_keywords = {}\n",
    "\n",
    "topics = {\n",
    "    0: \"Postive Trump Sentiment\",\n",
    "    1: \"Politcal Social Network\",\n",
    "    2: \"Negative Candaite Sentiment\",\n",
    "    3: \"Voter readiness and mobilization\"\n",
    "}\n",
    "\n",
    "for topic_idx, topic in enumerate(lda_model.components_):\n",
    "    top_words = [terms[i] for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "    topic_keywords[topic_idx] = top_words\n",
    "    print(f\"Topic #{topic_idx + 1} ({topics[topic_idx]}): {', '.join(top_words)}\")\n",
    "\n",
    "# Assign each document the most relevant topic\n",
    "topic_assignments = lda_model.transform(X)\n",
    "df['topic_id'] = topic_assignments.argmax(axis=1)\n",
    "\n",
    "# Map numerical topics to labels\n",
    "df['topic_label'] = df['topic_id'].map(topics)\n",
    "\n",
    "# If the 'caption' column is blank, do not assign a topic\n",
    "df.loc[df['original_caption'].isnull() | (df['original_caption'].str.strip() == ''), ['topic_id', 'topic_label']] = None\n",
    "\n",
    "# Print the dataframe with topics assigned\n",
    "print(df[['topic_model_clean', 'topic_label']].head(10))\n",
    "\n",
    "# Remove topic_model_clean\n",
    "df.drop('topic_model_clean', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the New CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the required columns for the new CSV file\n",
    "\n",
    "new_df = df[['caption_clean', 'image+caption_target', 'political_leaning', 'likes', 'retweet_count', 'comment_count', 'view_count', 'poster_follower_count', 'poster_frequency', 'total_posts', 'mentions', 'hashtags', 'urls', \n",
    "     'Positive', 'Neutral', 'Negative', 'Compound', 'Persons', 'Organizations', 'Locations', 'Nationalities/religiious groups', 'Date', 'topic_label', 'image_filename', 'comment_file', 'Post ID', 'URL to tweet', 'creation_date', 'poster_handle', 'poster_display_name',]]\n",
    "\n",
    "# Save the new DataFrame to a CSV file\n",
    "new_df.to_csv('Processed_Tweets.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
